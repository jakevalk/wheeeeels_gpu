{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e3da83",
   "metadata": {},
   "source": [
    "First we import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa0b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import statistics as cal\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889af901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0     frAcc   frRoAcc   frDispl  frRoAng   frSpeed  timeLine  \\\n",
      "299         299  0.002430 -0.000160 -0.090679 -0.21044 -0.000124      3.00   \n",
      "300         300 -0.014385 -0.000161 -0.092929 -0.23955 -0.000099      3.01   \n",
      "301         301 -0.001402 -0.000162 -0.095673 -0.30925 -0.000243      3.02   \n",
      "302         302 -0.007637 -0.000165 -0.098779 -0.31193 -0.000257      3.03   \n",
      "303         303  0.026330 -0.000168 -0.102200 -0.37210 -0.000334      3.04   \n",
      "..          ...       ...       ...       ...      ...       ...       ...   \n",
      "594         594 -0.016101 -0.001562 -0.855020 -0.24591 -0.000309      5.95   \n",
      "595         595 -0.033849 -0.001566 -0.857470 -0.24295 -0.000470      5.96   \n",
      "596         596  0.047428 -0.001572 -0.860010 -0.26550 -0.000809      5.97   \n",
      "597         597 -0.038892 -0.001578 -0.862210 -0.17479 -0.000334      5.98   \n",
      "598         598 -0.008833 -0.001584 -0.864330 -0.24918 -0.000723      5.99   \n",
      "\n",
      "     frameRotationalSpeedX  frameRotationalSpeedY  frameRotationalSpeedZ  \\\n",
      "299                 1.0500                0.93800                -1.0920   \n",
      "300                 1.0967                0.95667                -1.1200   \n",
      "301                 1.1200                0.91000                -1.1900   \n",
      "302                 0.9800                0.98000                -1.1900   \n",
      "303                 1.1830                0.91000                -1.2530   \n",
      "..                     ...                    ...                    ...   \n",
      "594                 1.1830                0.91700                -1.1270   \n",
      "595                 1.2600                0.98000                -1.1200   \n",
      "596                 1.1200                1.05000                -1.1200   \n",
      "597                 1.0500                0.98000                -1.0500   \n",
      "598                 1.1112                0.90125                -1.1288   \n",
      "\n",
      "     wheelRotationalSpeedX  wheelRotationalSpeedY  wheelRotationalSpeedZ  \\\n",
      "299                 1.5400                 1.3300                -1.4933   \n",
      "300                 1.5711                 1.2989                -1.5400   \n",
      "301                 1.6100                 1.3300                -1.4700   \n",
      "302                 1.6100                 1.4000                -1.4778   \n",
      "303                 1.6520                 1.4000                -1.5400   \n",
      "..                     ...                    ...                    ...   \n",
      "594                 1.5400                 1.2133                -1.4933   \n",
      "595                 1.5089                 1.2911                -1.5400   \n",
      "596                 1.4700                 1.3300                -1.5050   \n",
      "597                 1.4700                 1.3300                -1.4700   \n",
      "598                 1.4700                 1.3720                -1.4280   \n",
      "\n",
      "     frRoSpeed  Sum_WheelX_FrameZ  Div_FrameZ_WheelX  Filt_WheelX  \\\n",
      "299   -2.91050             0.4480          -0.709091     1.520674   \n",
      "300   -6.97020             0.4511          -0.712876     1.519791   \n",
      "301   -0.26817             0.4200          -0.739130     1.518986   \n",
      "302   -6.01720             0.4200          -0.739130     1.518258   \n",
      "303    7.06090             0.3990          -0.758475     1.517609   \n",
      "..         ...                ...                ...          ...   \n",
      "594    0.29582             0.4130          -0.731818     1.513743   \n",
      "595   -2.25500             0.3889          -0.742263     1.513452   \n",
      "596    9.07110             0.3500          -0.761905     1.513198   \n",
      "597   -7.43850             0.4200          -0.714286     1.512983   \n",
      "598   -6.75230             0.3412          -0.767891     1.512807   \n",
      "\n",
      "     Filt_FrameZ  Action  \n",
      "299    -0.515806     0.0  \n",
      "300    -0.554331     0.0  \n",
      "301    -0.593248     0.0  \n",
      "302    -0.632375     0.0  \n",
      "303    -0.671525     0.0  \n",
      "..           ...     ...  \n",
      "594    -1.120636     0.0  \n",
      "595    -1.120319     0.0  \n",
      "596    -1.120065     0.0  \n",
      "597    -1.119868     0.0  \n",
      "598    -1.119722     0.0  \n",
      "\n",
      "[300 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4455/2176787522.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.Action[df.Action == \"Sprinting\"] = 1\n"
     ]
    }
   ],
   "source": [
    "#load in df\n",
    "Player = 15\n",
    "Game = 2\n",
    "\n",
    "df = pd.read_csv('matrix_Player_' + str(Player) + '_game_' + str(Game) + '_Processed_Action.csv')\n",
    "# Fill NaN with 0\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.fillna(0)\n",
    "\n",
    "#Convert Sprinting to 1\n",
    "df.Action[df.Action == \"Sprinting\"] = 1\n",
    "\n",
    "#Delete first 99 rows, so df starts at timeLine == 1.00\n",
    "df = df.iloc[99: , :]\n",
    "print(df.iloc[200:500 , :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8638cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data into chunks of a second\n",
    "n = 100 #chunk size (100 datapoints in one second)\n",
    "chunks = [df[i:i+n] for i in range(0,df.shape[0],n)]\n",
    "#Set chunks into dataframe\n",
    "#for chunk in chunks:\n",
    "frames = []\n",
    "for chunk in chunks:\n",
    "    P = pd.DataFrame({'frAcc':[max(chunk['frAcc'].tolist())], \n",
    "                      'frRoAcc':[chunk['frRoAcc'].tolist()], 'frDispl':[chunk['frDispl'].tolist()], \n",
    "                      'frRoAng':[chunk['frRoAng'].tolist()], 'frSpeed':[max(chunk['frSpeed'].tolist())], \n",
    "                      'timeLine':[max(chunk['timeLine'].tolist())], 'frameRotationalSpeedX':[chunk['frameRotationalSpeedX'].tolist()], \n",
    "                      'frameRotationalSpeedY':[cal.mean(chunk['frameRotationalSpeedY'].tolist())], 'frameRotationalSpeedZ':[cal.mean(chunk['frameRotationalSpeedZ'].tolist())],\n",
    "                      'wheelRotationalSpeedX':[max(chunk['wheelRotationalSpeedX'].tolist())], 'wheelRotationalSpeedY':[chunk['wheelRotationalSpeedY'].tolist()],\n",
    "                      'wheelRotationalSpeedZ':[chunk['wheelRotationalSpeedZ'].tolist()], 'frRoSpeed':[max(chunk['frRoSpeed'].tolist())],\n",
    "                      'Sum_WheelX_FrameZ':[max(chunk['Sum_WheelX_FrameZ'].tolist())], 'Div_FrameZ_WheelX':[cal.mean(chunk['Div_FrameZ_WheelX'].tolist())],\n",
    "                      'Filt_WheelX':[cal.mean(chunk['Filt_WheelX'].tolist())], 'Filt_FrameZ':[cal.mean(chunk['Filt_FrameZ'].tolist())],\n",
    "                      'Action':[max(chunk['Action'].tolist())]})\n",
    "    frames.append(P)\n",
    "df = pd.concat(frames,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe65c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1990aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split chunk data into train test validate (with colum [sum and Div] as input, and action as output)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df[[\n",
    "                                                        'Sum_WheelX_FrameZ',\n",
    "                                                        'Div_FrameZ_WheelX',\n",
    "                                                        'wheelRotationalSpeedX',\n",
    "                                                        'Filt_FrameZ',\n",
    "                                                        'Filt_WheelX',\n",
    "                                                        'frameRotationalSpeedY'\n",
    "                                                       ]], \n",
    "                                                    df.Action.to_numpy().reshape(-1,1), test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab9e2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_valid = poly.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c278f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_valid = X_scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6299bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "y_valid = y_scaler.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fddb6a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TensorDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13719/3928212576.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TensorDataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "valid_ds = TensorDataset(torch.tensor(X_valid), torch.tensor(y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
